{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# #%% md\n",
    "# Shipper-Brand Relation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43393a88d8db239d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esse notebook tem por objetivo fazer a relação de empresas que importam somente uma marca, facilitando a relação importador-"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3547a85086aa1f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2247626460e056ff",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:31.696199300Z",
     "start_time": "2024-02-22T13:46:30.401651600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the modules needed\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "from src.data.dremio_utils import *\n",
    "# Data Handling\n",
    "from dotenv import dotenv_values \n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "\n",
    "# import pyspark.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"attributes_dict\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:36.885623300Z",
     "start_time": "2024-02-22T13:46:31.696199300Z"
    }
   },
   "id": "9f4b6b3ba58fedc9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "bds = BaseDremioService(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:36.901216500Z",
     "start_time": "2024-02-22T13:46:36.885623300Z"
    }
   },
   "id": "b958cb0ee3f1a4f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Getting Merged Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a857a09bd42d6f3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "grouped_data = spark.read.parquet(\"../data/processed/average_unity_price_historic.parquet\")\n",
    "grouped_data = grouped_data.dropna()\n",
    "grouped_data = grouped_data.filter(\n",
    "    (grouped_data.importador_uf != \"\") &\n",
    "    (grouped_data.importador_municipio != \"\")   \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:41.301089900Z",
     "start_time": "2024-02-22T13:46:36.901216500Z"
    }
   },
   "id": "890265008d0fe9c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "\n",
    "# MVP\n",
    "teste_base = {\"ncm\": ['123456','123456','123456','123456'],\n",
    "              \"importador_uf\": ['123456', '123456','123456','123456',],\n",
    "              \"ano\": [2018, 2018, 2019, 2020],\n",
    "              \"semestre\": [1,2,1,1],\n",
    "              \"valor_unitario\": [1.2, 1.1, 1.3, 1.4]}\n",
    "\n",
    "df_base = pd.DataFrame(teste_base)\n",
    "df_base[\"ano_semestre\"] = df_base[\"ano\"]*100 + df_base[\"semestre\"]\n",
    "\n",
    "new_data = {\"ano\": [2024, 2024],\n",
    "            \"semestre\": [1,2]}\n",
    "df_new_data = pd.DataFrame(new_data)\n",
    "\n",
    "df_new_data[\"ncm\"] = \"123456\"\n",
    "df_new_data[\"importador_uf\"] = \"123456\"\n",
    "df_new_data[\"ano_semestre\"] = df_new_data[\"ano\"]*100 + df_new_data[\"semestre\"]\n",
    "\n",
    "df_last = pd.concat([df_base, df_new_data])\n",
    "# df_last[\"ano_semestre\"] = df_last[\"ano\"]*100 + df_last[\"semestre\"] \n",
    "z = np.polyfit(df_base[\"ano_semestre\"], df_base[\"valor_unitario\"], 1)\n",
    "p = np.poly1d(z)\n",
    "p(df_last[\"ano_semestre\"])\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d0cd3a0c7c4dc1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Usage in the grouped dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5b0ffaee94ce58b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.1 Create the data to be trended"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd1e99698efc09c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "new_data = [(2024, 1), (2024, 2)]\n",
    "new_data_schema =StructType([\n",
    "    StructField(\"ano\", IntegerType()),\n",
    "    StructField(\"semestre\", IntegerType())\n",
    "])\n",
    " \n",
    "df_new_data = spark.createDataFrame(data=new_data, schema=new_data_schema)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:41.379591800Z",
     "start_time": "2024-02-22T13:46:41.301089900Z"
    }
   },
   "id": "cdd600852d4dc541"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 Create the X-axis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a0d25981385f67"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+\n",
      "| ano|semestre|ano_semestre|\n",
      "+----+--------+------------+\n",
      "|2024|       1|      202401|\n",
      "|2024|       2|      202402|\n",
      "+----+--------+------------+\n"
     ]
    }
   ],
   "source": [
    "df_new_data = df_new_data.withColumn(\"ano_semestre\", df_new_data.ano*100 + df_new_data.semestre)\n",
    "df_new_data.show(5)\n",
    "# df_new_data.withColumn(\"ano_semestre\", df_new_data.ano*100 + df_new_data.semestre)\n",
    "# grouped_data[\"ano_semestre\"] = grouped_data[\"ano\"]*100 + grouped_data[\"semestre\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:42.687212700Z",
     "start_time": "2024-02-22T13:46:41.379591800Z"
    }
   },
   "id": "7b28127cb69eea21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.3 Iter over the groups"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e113501add3fc8a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@pandas_udf(StructType([\n",
    "    StructField(\"ncm\", IntegerType()),\n",
    "    StructField(\"importador_municipio\", IntegerType()),\n",
    "    StructField(\"id_pais_origem\", IntegerType()),\n",
    "    StructField(\"avg_valor_item\", DoubleType())\n",
    "]), PandasUDFType.GROUPED_MAP)\n",
    "def calculate_trend_line(pdf):\n",
    "    z = np.polyfit(pdf[\"ano_semestre\"], pdf[\"avg_valor_item\"], 1)\n",
    "    p = np.poly1d(z)\n",
    "    pdf[\"avg_valor_item\"] = p(pdf[\"ano_semestre\"])\n",
    "    return pdf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:42.849607900Z",
     "start_time": "2024-02-22T13:46:42.687212700Z"
    }
   },
   "id": "444ec4d943540ffa"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid function: pandas_udf with function type GROUPED_MAP or the function in groupby.applyInPandas must take either one argument (data) or two arguments (key, data).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Apply the UDF to each group\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# window_spec = Window.partitionBy(\"ncm\", \"importador_municipio\", \"id_pais_origem\")\u001B[39;00m\n\u001B[0;32m      3\u001B[0m grouped_schema \u001B[38;5;241m=\u001B[39m StructType([\n\u001B[0;32m      4\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mncm\u001B[39m\u001B[38;5;124m\"\u001B[39m, IntegerType()),\n\u001B[0;32m      5\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimportador_municipio\u001B[39m\u001B[38;5;124m\"\u001B[39m, IntegerType()),\n\u001B[0;32m      6\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid_pais_origem\u001B[39m\u001B[38;5;124m\"\u001B[39m, IntegerType()),\n\u001B[0;32m      7\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavg_valor_item\u001B[39m\u001B[38;5;124m\"\u001B[39m, DoubleType())\n\u001B[0;32m      8\u001B[0m ])\n\u001B[1;32m----> 9\u001B[0m df_trend \u001B[38;5;241m=\u001B[39m \u001B[43mgrouped_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mncm\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimportador_municipio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid_pais_origem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplyInPandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_trend_line\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrouped_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# #df_trend = grouped_data.withColumn(\"row_num\", col(\"ncm\")).withColumn(\"row_num\", col(\"row_num\").over(window_spec))\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Spark\\python\\pyspark\\sql\\pandas\\group_ops.py:178\u001B[0m, in \u001B[0;36mPandasGroupedOpsMixin.applyInPandas\u001B[1;34m(self, func, schema)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pandas_udf, PandasUDFType\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, GroupedData)\n\u001B[1;32m--> 178\u001B[0m udf \u001B[38;5;241m=\u001B[39m \u001B[43mpandas_udf\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturnType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctionType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPandasUDFType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGROUPED_MAP\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    180\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df\n\u001B[0;32m    181\u001B[0m udf_column \u001B[38;5;241m=\u001B[39m udf(\u001B[38;5;241m*\u001B[39m[df[col] \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns])\n",
      "File \u001B[1;32mC:\\Spark\\python\\pyspark\\sql\\pandas\\functions.py:370\u001B[0m, in \u001B[0;36mpandas_udf\u001B[1;34m(f, returnType, functionType)\u001B[0m\n\u001B[0;32m    368\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m functools\u001B[38;5;241m.\u001B[39mpartial(_create_pandas_udf, returnType\u001B[38;5;241m=\u001B[39mreturn_type, evalType\u001B[38;5;241m=\u001B[39meval_type)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 370\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_create_pandas_udf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturnType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevalType\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_type\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Spark\\python\\pyspark\\sql\\pandas\\functions.py:414\u001B[0m, in \u001B[0;36m_create_pandas_udf\u001B[1;34m(f, returnType, evalType)\u001B[0m\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    408\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid function: 0-arg pandas_udfs are not supported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    409\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstead, create a 1-arg pandas_udf and ignore the arg in your function.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m     )\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evalType \u001B[38;5;241m==\u001B[39m PythonEvalType\u001B[38;5;241m.\u001B[39mSQL_GROUPED_MAP_PANDAS_UDF \\\n\u001B[0;32m    413\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(argspec\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid function: pandas_udf with function type GROUPED_MAP or \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe function in groupby.applyInPandas \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmust take either one argument (data) or two arguments (key, data).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evalType \u001B[38;5;241m==\u001B[39m PythonEvalType\u001B[38;5;241m.\u001B[39mSQL_COGROUPED_MAP_PANDAS_UDF \\\n\u001B[0;32m    420\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(argspec\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m    421\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    422\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid function: the function in cogroup.applyInPandas \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    423\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmust take either two arguments (left, right) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    424\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor three arguments (key, left, right).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid function: pandas_udf with function type GROUPED_MAP or the function in groupby.applyInPandas must take either one argument (data) or two arguments (key, data)."
     ]
    }
   ],
   "source": [
    "# Apply the UDF to each group\n",
    "# window_spec = Window.partitionBy(\"ncm\", \"importador_municipio\", \"id_pais_origem\")\n",
    "grouped_schema = StructType([\n",
    "    StructField(\"ncm\", IntegerType()),\n",
    "    StructField(\"importador_municipio\", IntegerType()),\n",
    "    StructField(\"id_pais_origem\", IntegerType()),\n",
    "    StructField(\"avg_valor_item\", DoubleType())\n",
    "])\n",
    "df_trend = grouped_data.groupBy(\"ncm\", \"importador_municipio\", \"id_pais_origem\").applyInPandas(calculate_trend_line, schema=grouped_schema)\n",
    "# #df_trend = grouped_data.withColumn(\"row_num\", col(\"ncm\")).withColumn(\"row_num\", col(\"row_num\").over(window_spec))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:48:30.378717300Z",
     "start_time": "2024-02-22T13:48:30.284559Z"
    }
   },
   "id": "4d1d6ef74fa57ed8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_trend.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:42.994540400Z"
    }
   },
   "id": "a517d8af9a1a50ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Only the useful data\n",
    "grouped_count[\"combinations\"] =  grouped_count['ncm'].astype(str) + grouped_count['importador_municipio'] + grouped_count['id_pais_origem']\n",
    "better_combinations = grouped_count[grouped_count[\"key\"]>2][\"combinations\"].to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:42.994540400Z"
    }
   },
   "id": "12244fa156e1a594"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups_qtd = grouped_data[['ncm', 'importador_municipio', 'id_pais_origem']].drop_duplicates().shape[0]\n",
    "groups_qtd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:43.000679700Z",
     "start_time": "2024-02-22T13:46:43.000422700Z"
    }
   },
   "id": "f0102c1af775b251"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\".join(str(key)).replace(\"(\",\"\").replace(\")\",\"\").replace(\", \",\"\").replace(\"''\",\"_\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:46:43.032079Z",
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "45d56237d154811f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_data[['ncm', 'importador_municipio', 'id_pais_origem']].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "75daea732da04d85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_id = 0\n",
    "grouped = grouped_data.copy()\n",
    "grouped[\"key\"] = grouped['ncm'].astype(str) + grouped['importador_municipio'] + grouped['id_pais_origem']\n",
    "grou\n",
    "grouped = grouped_data.groupby(['ncm', 'importador_municipio', 'id_pais_origem'])\n",
    "grouped[\"key\"] = grouped['ncm'].astype(str) + grouped['importador_municipio'] + grouped['id_pais_origem']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "b60175a39640a738"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tqdm(total = groups_qtd, desc=\"Creating a trend line for unity price\") as pbar:\n",
    "    for key, df_group in grouped:\n",
    "        # print(key)\n",
    "        df_aux_hist = grouped_data[\n",
    "                            (grouped_data['ncm'] == key[0]) &\n",
    "                            (grouped_data['importador_municipio'] == key[1]) &\n",
    "                            (grouped_data['id_pais_origem'] == key[2])].copy()\n",
    "        \n",
    "        df_aux_trend = df_new_data.copy()\n",
    "        \n",
    "        z = np.polyfit(df_aux_hist[\"ano_semestre\"], df_aux_hist[\"avg_valor_item\"], 1)\n",
    "        p = np.poly1d(z)\n",
    "        df_aux_trend['ncm'] = key[0]\n",
    "        df_aux_trend['importador_municipio'] = key[1]\n",
    "        df_aux_trend['id_pais_origem'] = key[2]\n",
    "        df_aux_trend[\"avg_valor_item\"] = p(df_aux_trend[\"ano_semestre\"])\n",
    "        \n",
    "        df_final = pd.concat([df_group, df_aux_trend])\n",
    "        key_to_save = \"\".join(str(key)).replace(\"(\",\"\").replace(\")\",\"\").replace(\", \",\"\").replace(\"''\",\"_\")\n",
    "        df_final.to_parquet(f\"../data/processed/trend_values/{file_id}.parquet\")\n",
    "        file_id += 1\n",
    "        pbar.update(1)\n",
    "        # print(df_final)\n",
    "        # break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "33fc03dc49aec867"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Iteração sobre os grupos "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da18f3ad6a0b876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, df_group in grouped_data.groupby(['ncm', 'importador_uf', 'importador_municipio', 'urf', 'id_pais_origem']):\n",
    "    df_group = \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "8e9ea8a69fd5f2fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_group['importador_uf'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "e56c09690157b9b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years_df = pd.DataFrame.from_dict({\"ano\": [2018, 2019, 2020, 2021, 2022, 2023]})\n",
    "semesters_df = pd.DataFrame.from_dict({\"semestre\":[1, 2]})\n",
    "gabarito_datas = years_df.join(semesters_df, how=\"cross\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "443963ec9c879ca6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gabarito_comb = unique_combinations.join(gabarito_datas, how=\"cross\")\n",
    "gabarito_comb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "c270ff65c1823768"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2b_filled = gabarito_comb.merge(grouped_data, how=\"left\", on=['ncm', 'importador_uf', 'importador_municipio', 'urf', 'id_pais_origem', 'ano', 'semestre'])\n",
    "df_2b_filled.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.000679700Z"
    }
   },
   "id": "bfc7c07e1f5179ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_filled = df_2b_filled.copy()\n",
    "df_filled[\"avg_valor_item\"] = df_filled[\"avg_valor_item\"].interpolate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "666c0d377be86c49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_filled.tail(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "840b689783d6d77a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Inference of the value for the first semesters of 2024"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3db62a2081e302a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Inference using linear interpolation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cf18a1cec0190c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years_df = pd.DataFrame.from_dict({\"ano\": [2018, 2019, 2020, 2021, 2022, 2023, 2024]})\n",
    "semesters_df = pd.DataFrame.from_dict({\"semestre\": [1, 2]})\n",
    "gabarito_datas = years_df.join(semesters_df, how=\"cross\")\n",
    "gabarito_comb = unique_combinations.join(gabarito_datas, how=\"cross\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "b9b331a51addcfd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2b_infer = gabarito_comb.merge(df_filled, how=\"left\", on=['ncm', 'importador_uf', 'importador_municipio', 'urf', 'name_pt', 'ano', 'semestre'])\n",
    "df_2b_infer.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "b4b95d3b12807459"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2b_infer[\"avg_valor_item\"] = df_2b_infer[\"avg_valor_item\"].interpolate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "858fc6f1a6bc6654"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2b_infer[\"anosem\"] = df_2b_infer[\"ano\"].astype(str) + df_2b_infer[\"semestre\"].astype(str) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "5fb17ca1c18b74a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for _, df in df_2b_infer.groupby(['ncm', 'importador_uf', 'importador_municipio', 'urf', 'name_pt']):\n",
    "    print(df[\"avg_valor_item\"].values)\n",
    "    df.plot(y=\"avg_valor_item\", x=\"anosem\")\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-22T13:46:43.016308900Z"
    }
   },
   "id": "74dccca8b519100f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Inference using linear interpolation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f3311143168a90b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
