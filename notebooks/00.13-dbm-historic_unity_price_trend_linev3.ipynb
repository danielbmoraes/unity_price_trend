{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36438603a2e816df",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:05:50.962515700Z",
     "start_time": "2024-03-18T14:05:50.931299500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.utils import get_logger\n",
    "import logging\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger = get_logger(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 11:06:08,260 - __main__ - INFO - Filtrando e corrigindo dados\n",
      "2024-03-18 11:06:17,600 - __main__ - INFO - \tajustando importador UF\n",
      "2024-03-18 11:07:06,364 - __main__ - INFO - \tajustando importador municipio\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "grouped_data = pd.read_parquet(\"../data/processed/average_unity_price_historic.parquet\")\n",
    "\n",
    "logger.info(\"Filtrando e corrigindo dados\")\n",
    "\n",
    "# Deleting all null values and empty spaces in important columns\n",
    "grouped_data.dropna(inplace=True)\n",
    "grouped_data = grouped_data[(grouped_data[\"importador_uf\"] != \"\") \\\n",
    "                            & (grouped_data[\"importador_municipio\"] != \"\")].copy()\n",
    "\n",
    "# Correction of states and counties\n",
    "estados_br = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\",\n",
    "              \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\", \"DF\"]\n",
    "\n",
    "grouped_data[\"old_municipio\"] = grouped_data[\"importador_municipio\"]\n",
    "\n",
    "# Treating the data\n",
    "\n",
    "logger.info(\"\\tajustando importador UF\")\n",
    "grouped_data[\"importador_uf_new\"] = grouped_data.apply(lambda x: x[\"importador_uf\"] \\\n",
    "    if x[\"importador_uf\"] in estados_br else x[\"importador_municipio\"], axis=1)\n",
    "\n",
    "logger.info(\"\\tajustando importador municipio\")\n",
    "grouped_data[\"importador_municipio_new\"] = grouped_data.apply(lambda x: x[\"old_municipio\"] \\\n",
    "    if x[\"old_municipio\"] not in estados_br else x[\"importador_uf\"], axis=1)\n",
    "\n",
    "grouped_data.drop(columns=['importador_municipio', \"importador_uf\", \"old_municipio\"], inplace=True)\n",
    "grouped_data.rename(columns={\"importador_municipio_new\": \"importador_municipio\",\n",
    "                   \"importador_uf_new\": \"importador_uf\"}, inplace=True)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:07:54.433086400Z",
     "start_time": "2024-03-18T14:05:50.962515700Z"
    }
   },
   "id": "cd2b385032af917d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "grouped_data = grouped_data.groupby(['ncm', 'importador_uf', 'importador_municipio', 'urf', 'id_pais_origem',\n",
    "                                     'ano', 'semestre'], as_index=False).mean('avg_valor_item')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:04.839545500Z",
     "start_time": "2024-03-18T14:07:54.464431Z"
    }
   },
   "id": "51a9761041809647"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 11:08:04,843 - __main__ - INFO - Criando dataframes de datas\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Criando dataframes de datas\")\n",
    "# Creation of historic dates template\n",
    "years_df = pd.DataFrame.from_dict({\"ano\": [2018, 2019, 2020, 2021, 2022, 2023]})\n",
    "# years_df = pd.DataFrame.from_dict({\"ano\": [2022, 2023]})\n",
    "semesters_df = pd.DataFrame.from_dict({\"semestre\": [1, 2]})\n",
    "dates_template = years_df.join(semesters_df, how=\"cross\")\n",
    "dates_template[\"ano_semestre\"] = dates_template[\"ano\"] * 100 + dates_template[\"semestre\"]\n",
    "dates_template = dates_template[dates_template[\"ano_semestre\"] < 20232]\n",
    "dates_template.drop(columns=[\"ano\", \"semestre\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:04.904708600Z",
     "start_time": "2024-03-18T14:08:04.843564Z"
    }
   },
   "id": "3c0ddf1262e954ea"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Creation of dates template for the trend line\n",
    "new_data = {\"ano\": [2023],\n",
    "            \"semestre\": [2]}\n",
    "df_new_data = pd.DataFrame(new_data)\n",
    "df_new_data[\"ano_semestre\"] = df_new_data[\"ano\"] * 100 + df_new_data[\"semestre\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:04.920334900Z",
     "start_time": "2024-03-18T14:08:04.889027100Z"
    }
   },
   "id": "49ad4c8825bd9dd9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 11:08:04,904 - __main__ - INFO - Filtrando dataframe somente com chaves válidas não processadas\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Filtrando dataframe somente com chaves válidas não processadas\")\n",
    "\n",
    "# Reading the data already processed (create a empty dataframe if theres no processed data)\n",
    "if os.path.isfile(\"../data/processed/pd_trended_data_interpolated.parquet\"):\n",
    "    df_total = pd.read_parquet(\"../data/processed/pd_trended_data_interpolated.parquet\")\n",
    "\n",
    "    # Creating the list of already processed and valid keys\n",
    "    keys_processed = df_total[['id_pais_origem', 'ncm', 'importador_municipio', 'urf']].drop_duplicates()\n",
    "    keys_processed[\"key\"] = keys_processed[\"ncm\"].astype(str) + '-' + keys_processed[\"id_pais_origem\"] + '-' + \\\n",
    "                            keys_processed['importador_municipio'] + '-' + keys_processed['urf']\n",
    "\n",
    "    already_processed = keys_processed[\"key\"].to_list()\n",
    "\n",
    "else:\n",
    "    df_total = pd.DataFrame()\n",
    "    already_processed = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:06.287408Z",
     "start_time": "2024-03-18T14:08:04.904708600Z"
    }
   },
   "id": "2f87a98785b6bd0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "already_processed = []\n",
    "df_total = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:06.318462300Z",
     "start_time": "2024-03-18T14:08:06.302881300Z"
    }
   },
   "id": "f95dead5a49b152b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                 ncm importador_uf importador_municipio  \\\n0         1012100.00            GO              FORMOSA   \n1         1012100.00            GO              FORMOSA   \n2         1012100.00            MG        BOA ESPERANCA   \n3         1012100.00            MG        BOA ESPERANCA   \n4         1012100.00            MG           MATOZINHOS   \n...              ...           ...                  ...   \n4582695  97069000.00            SP            SAO PAULO   \n4582696  99999942.00            GO             ANAPOLIS   \n4582697  99999942.00            GO             ANAPOLIS   \n4582698  99999942.00            GO             ANAPOLIS   \n4582699  99999942.00            GO             ANAPOLIS   \n\n                                                    urf  id_pais_origem   ano  \\\n0                  AEROPORTO INTERNACIONAL DE VIRACOPOS  ESTADOS UNIDOS  2020   \n1                  AEROPORTO INTERNACIONAL DE VIRACOPOS  ESTADOS UNIDOS  2021   \n2                  AEROPORTO INTERNACIONAL DE VIRACOPOS  ESTADOS UNIDOS  2019   \n3                  AEROPORTO INTERNACIONAL DE VIRACOPOS          FRANÇA  2021   \n4                  AEROPORTO INTERNACIONAL DE VIRACOPOS         BÉLGICA  2019   \n...                                                 ...             ...   ...   \n4582695  AEROPORTO INTERNACIONAL DE SAO PAULO/GUARULHOS          FRANÇA  2022   \n4582696             AEROPORTO INTERNACIONAL DE BRASÍLIA          SUÉCIA  2019   \n4582697             AEROPORTO INTERNACIONAL DE BRASÍLIA          SUÉCIA  2021   \n4582698             AEROPORTO INTERNACIONAL DE BRASÍLIA          SUÉCIA  2021   \n4582699            AEROPORTO INTERNACIONAL DE VIRACOPOS          SUÉCIA  2021   \n\n         semestre  avg_valor_item  ano_semestre  \n0               2    12900.000000      202002.0  \n1               1    10000.000000      202101.0  \n2               1    27120.000000      201901.0  \n3               2    17621.890625      202102.0  \n4               2     1782.250000      201902.0  \n...           ...             ...           ...  \n4582695         2    50000.000000      202202.0  \n4582696         2   197342.593750      201902.0  \n4582697         1   139064.257778      202101.0  \n4582698         2    65031.512500      202102.0  \n4582699         1    59292.040000      202101.0  \n\n[4582700 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ncm</th>\n      <th>importador_uf</th>\n      <th>importador_municipio</th>\n      <th>urf</th>\n      <th>id_pais_origem</th>\n      <th>ano</th>\n      <th>semestre</th>\n      <th>avg_valor_item</th>\n      <th>ano_semestre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1012100.00</td>\n      <td>GO</td>\n      <td>FORMOSA</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>ESTADOS UNIDOS</td>\n      <td>2020</td>\n      <td>2</td>\n      <td>12900.000000</td>\n      <td>202002.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1012100.00</td>\n      <td>GO</td>\n      <td>FORMOSA</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>ESTADOS UNIDOS</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>10000.000000</td>\n      <td>202101.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1012100.00</td>\n      <td>MG</td>\n      <td>BOA ESPERANCA</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>ESTADOS UNIDOS</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>27120.000000</td>\n      <td>201901.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1012100.00</td>\n      <td>MG</td>\n      <td>BOA ESPERANCA</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>FRANÇA</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>17621.890625</td>\n      <td>202102.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1012100.00</td>\n      <td>MG</td>\n      <td>MATOZINHOS</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>BÉLGICA</td>\n      <td>2019</td>\n      <td>2</td>\n      <td>1782.250000</td>\n      <td>201902.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4582695</th>\n      <td>97069000.00</td>\n      <td>SP</td>\n      <td>SAO PAULO</td>\n      <td>AEROPORTO INTERNACIONAL DE SAO PAULO/GUARULHOS</td>\n      <td>FRANÇA</td>\n      <td>2022</td>\n      <td>2</td>\n      <td>50000.000000</td>\n      <td>202202.0</td>\n    </tr>\n    <tr>\n      <th>4582696</th>\n      <td>99999942.00</td>\n      <td>GO</td>\n      <td>ANAPOLIS</td>\n      <td>AEROPORTO INTERNACIONAL DE BRASÍLIA</td>\n      <td>SUÉCIA</td>\n      <td>2019</td>\n      <td>2</td>\n      <td>197342.593750</td>\n      <td>201902.0</td>\n    </tr>\n    <tr>\n      <th>4582697</th>\n      <td>99999942.00</td>\n      <td>GO</td>\n      <td>ANAPOLIS</td>\n      <td>AEROPORTO INTERNACIONAL DE BRASÍLIA</td>\n      <td>SUÉCIA</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>139064.257778</td>\n      <td>202101.0</td>\n    </tr>\n    <tr>\n      <th>4582698</th>\n      <td>99999942.00</td>\n      <td>GO</td>\n      <td>ANAPOLIS</td>\n      <td>AEROPORTO INTERNACIONAL DE BRASÍLIA</td>\n      <td>SUÉCIA</td>\n      <td>2021</td>\n      <td>2</td>\n      <td>65031.512500</td>\n      <td>202102.0</td>\n    </tr>\n    <tr>\n      <th>4582699</th>\n      <td>99999942.00</td>\n      <td>GO</td>\n      <td>ANAPOLIS</td>\n      <td>AEROPORTO INTERNACIONAL DE VIRACOPOS</td>\n      <td>SUÉCIA</td>\n      <td>2021</td>\n      <td>1</td>\n      <td>59292.040000</td>\n      <td>202101.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4582700 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:06.366043300Z",
     "start_time": "2024-03-18T14:08:06.318462300Z"
    }
   },
   "id": "32ba086bc3531ccc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Filtering only for the data in the last five years\n",
    "\n",
    "# ToDo: Separar somente o que for de 2023 pra trás\n",
    "# grouped_data = grouped_data[(grouped_data[\"ano_semestre\"] < 202302) & (grouped_data[\"ano_semestre\"] > 202201)]\n",
    "\n",
    "\n",
    "grouped_data[\"key\"] = grouped_data[\"ncm\"].astype(str) + '-' + grouped_data[\"id_pais_origem\"] + '-' + \\\n",
    "                      grouped_data['importador_municipio'] + '-' + grouped_data['urf']\n",
    "\n",
    "\n",
    "selected_group = grouped_data[(grouped_data[\"ano_semestre\"] == 202302) & (grouped_data[\"avg_valor_item\"] > 0)]\n",
    "selected_keys = selected_group[\"key\"].unique()\n",
    "grouped_data = grouped_data[grouped_data[\"ano_semestre\"] < 202302]\n",
    "\n",
    "\n",
    "# Filtering the keys that is constantily repeated (so we could make a good trend line)\n",
    "count = pd.DataFrame(grouped_data[\"key\"].value_counts())\n",
    "threshold_count = 2\n",
    "count = count[count[\"key\"] >= threshold_count].copy()\n",
    "keys_2_process = count.reset_index()[\"index\"].to_list()\n",
    "\n",
    "# Filtering the dataset for keys not processed and recurrent keys\n",
    "grouped_data = grouped_data[~grouped_data[\"key\"].isin(already_processed)]\n",
    "grouped_data = grouped_data[grouped_data[\"key\"].isin(keys_2_process)]\n",
    "grouped_data = grouped_data[grouped_data[\"key\"].isin(selected_keys)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:12.383646600Z",
     "start_time": "2024-03-18T14:08:06.366043300Z"
    }
   },
   "id": "54ee906830415dd0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:12.383646600Z",
     "start_time": "2024-03-18T14:08:12.367924500Z"
    }
   },
   "id": "4fabde5b8c868f21"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1334531"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:12.414900Z",
     "start_time": "2024-03-18T14:08:12.383646600Z"
    }
   },
   "id": "d4534abce6cba145"
  },
  {
   "cell_type": "markdown",
   "source": [
    "grouped_data[\n",
    "(grouped_data['id_pais_origem'] == key[0]) &\n",
    "(grouped_data['ncm'] == key[1]) &\n",
    "(grouped_data['importador_municipio'] == key[2]) &\n",
    "(grouped_data['importador_uf'] == key[3]) &\n",
    "(grouped_data['urf'] == key[4])\n",
    "].groupby([\"ano_semestre\"], as_index=False).mean(\"avg_valor_item\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7613ff047bd3e653"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "grouped_data[\"ncm\"] = grouped_data[\"ncm\"].astype(int) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:08:12.595712500Z",
     "start_time": "2024-03-18T14:08:12.501651600Z"
    }
   },
   "id": "6b22a3dd5c49247c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Criando linha de tendencia para preco unitario:   1%|          | 2999/242791 [09:03<12:04:51,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Iniciando criacao da linha\")\n",
    "file_count = 0\n",
    "grouped = grouped_data.groupby(['id_pais_origem', 'ncm', 'importador_municipio', 'importador_uf' ,'urf'])\n",
    "groups_qtd = grouped_data[['id_pais_origem', 'ncm', 'importador_municipio', 'importador_uf' ,'urf']].drop_duplicates().shape[0]\n",
    "with tqdm(total=groups_qtd, desc=\"Criando linha de tendencia para preco unitario\") as pbar:\n",
    "    for key, df_group in grouped:\n",
    "\n",
    "        df_aux_hist = grouped_data[\n",
    "            (grouped_data['id_pais_origem'] == key[0]) &\n",
    "            (grouped_data['ncm'] == key[1]) &\n",
    "            (grouped_data['importador_municipio'] == key[2]) &\n",
    "            (grouped_data['importador_uf'] == key[3]) &\n",
    "            (grouped_data['urf'] == key[4])\n",
    "            ].groupby([\"ano_semestre\"], as_index=False).mean(\"avg_valor_item\")\n",
    "\n",
    "        group_key = key[0] + '-' + key[1].astype(str) + '-' + key[2] + '-' + key[3]\n",
    "        if (df_aux_hist.shape[0] > 0) and (group_key not in already_processed):\n",
    "            if len(df_aux_hist[\"ano_semestre\"].unique()) < 2:\n",
    "                # Interpolate if it hasn't enough data to infer\n",
    "                gabarito_aux = dates_template.copy()\n",
    "                df_aux_hist = gabarito_aux.merge(df_aux_hist, on=['ano_semestre'], how='left')\n",
    "                df_aux_hist[\"ano\"] = df_aux_hist['ano_semestre'].astype(str).str[:4]\n",
    "                df_aux_hist[\"semestre\"] = df_aux_hist['ano_semestre'].astype(str).str[-1:]\n",
    "                df_aux_hist[\"avg_valor_item\"] = df_aux_hist[\"avg_valor_item\"].interpolate()\n",
    "                df_aux_hist.dropna(axis=0, inplace=True)\n",
    "\n",
    "            df_aux_trend = df_new_data.copy()\n",
    "            to_create_trend = df_aux_hist[df_aux_hist[\"ano_semestre\"]>20221].copy()\n",
    "            if to_create_trend.shape[0] > 0:\n",
    "                z = np.polyfit(to_create_trend[\"ano_semestre\"], to_create_trend[\"avg_valor_item\"], 1)\n",
    "                p = np.poly1d(z)\n",
    "                df_aux_trend[\"avg_valor_item\"] = p(df_aux_trend[\"ano_semestre\"])\n",
    "    \n",
    "                final_aux = pd.concat([df_aux_hist, df_aux_trend])\n",
    "                final_aux['id_pais_origem'] = key[0]\n",
    "                final_aux['ncm'] = key[1]\n",
    "                final_aux['importador_municipio'] = key[2]\n",
    "                final_aux['importador_uf'] = key[3]\n",
    "                final_aux['urf'] = key[4]\n",
    "                final_aux[\"ano\"] = final_aux[\"ano\"].astype(int)\n",
    "                final_aux[\"semestre\"] = final_aux[\"semestre\"].astype(int)\n",
    "    \n",
    "                df_total = pd.concat([df_total, final_aux])\n",
    "                file_count += 1\n",
    "    \n",
    "                # For each 200 groups processed, it'll update the final dataframe\n",
    "                # if file_count % 200 == 0:\n",
    "                if file_count % 1000 == 0:\n",
    "                    df_total.to_parquet(f\"../data/processed/trend_values_v4/trend_lines_{int(file_count/1000)}.parquet\", index=False)\n",
    "                    df_total = pd.DataFrame()\n",
    "                    clear_output()\n",
    "                if file_count % 3000 == 0:\n",
    "                    break\n",
    "                   \n",
    "        pbar.update(1)\n",
    "        \n",
    "df_total.to_parquet(f\"../data/processed/trend_values_v4/trend_lines_end.parquet\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af194008631af560"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# At the end, it should save at the end of executors\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path(\"../data/processed/exp_g3/\")\n",
    "full_df = pd.concat(\n",
    "    pd.read_parquet(parquet_file)\n",
    "    for parquet_file in data_dir.glob('*.parquet')\n",
    ")\n",
    "full_df.to_parquet('../data/processed/trend_values_v4/trended_datav4_interpolated.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:18:20.181722200Z",
     "start_time": "2024-03-18T14:18:19.600508900Z"
    }
   },
   "id": "37772ff41a35fee8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import coalesce\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType, TimestampType"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T14:09:09.943825800Z"
    }
   },
   "id": "59730d9f5ac1516e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"attributes_dict\").getOrCreate()\n",
    "df = spark.read.parquet(\"../data/processed/trend_values/\")\n",
    "df.coalesce(1).write.parquet('../data/processed/trended_data_interpolated.parquet')\n",
    "spark.sparkContext.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-18T14:09:09.943825800Z"
    }
   },
   "id": "695b2b80c8f78938"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
